{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"41_Word_Embeddings.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","metadata":{"id":"7SN5USFEIIK3"},"source":["# **Word embeddings**"]},{"cell_type":"markdown","metadata":{"id":"Q6mJg1g3apaz"},"source":["Today we will introduce word embeddings. We will train our own word embeddings using a simple Keras model for a sentiment classification task, and then visualize them in the [Embedding Projector](http://projector.tensorflow.org) (shown in the image below). \n","\n","<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/images/embedding.jpg?raw=1\" alt=\"Screenshot of the embedding projector\" width=\"400\"/>\n","\n","## **Representing text as numbers**\n","\n","Machine learning models take vectors (arrays of numbers) as input. When working with text, the first thing you must do is come up with a strategy to convert strings to numbers (or to \"vectorize\" the text) before feeding it to the model. In this section, you will look at three strategies for doing so.\n","\n","### **One-hot encodings**\n","\n","As a first idea, you might \"one-hot\" encode each word in your vocabulary. Consider the sentence \"The cat sat on the mat\". The vocabulary (or unique words) in this sentence is (cat, mat, on, sat, the). To represent each word, you will create a zero vector with length equal to the vocabulary, then place a one in the index that corresponds to the word. This approach is shown in the following diagram.\n","\n","<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/images/one-hot.png?raw=1\" alt=\"Diagram of one-hot encodings\" width=\"400\" />\n","\n","To create a vector that contains the encoding of the sentence, you could then concatenate the one-hot vectors for each word.\n","\n","Key point: This approach is inefficient. A one-hot encoded vector is sparse (meaning, most indices are zero). Imagine you have 10,000 words in the vocabulary. To one-hot encode each word, you would create a vector where 99.99% of the elements are zero.\n","\n","### Encode each word with a unique number\n","\n","A second approach you might try is to encode each word using a unique number. Continuing the example above, you could assign 1 to \"cat\", 2 to \"mat\", and so on. You could then encode the sentence \"The cat sat on the mat\" as a dense vector like [5, 1, 4, 3, 5, 2]. This appoach is efficient. Instead of a sparse vector, you now have a dense one (where all elements are full).\n","\n","There are two downsides to this approach, however:\n","\n","* The integer-encoding is arbitrary (it does not capture any relationship between words).\n","\n","* An integer-encoding can be challenging for a model to interpret. A linear classifier, for example, learns a single weight for each feature. Because there is no relationship between the similarity of any two words and the similarity of their encodings, this feature-weight combination is not meaningful.\n","\n","### **Word embeddings**\n","\n","Word embeddings give us a way to use an efficient, dense representation in which similar words have a similar encoding. Importantly, you do not have to specify this encoding by hand. An embedding is a dense vector of floating point values (the length of the vector is a parameter you specify). Instead of specifying the values for the embedding manually, they are trainable parameters (weights learned by the model during training, in the same way a model learns weights for a dense layer). It is common to see word embeddings that are 8-dimensional (for small datasets), up to 1024-dimensions when working with large datasets. A higher dimensional embedding can capture fine-grained relationships between words, but takes more data to learn.\n","\n","<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/images/embedding2.png?raw=1\" alt=\"Diagram of an embedding\" width=\"400\"/>\n","\n","Above is a diagram for a word embedding. Each word is represented as a 4-dimensional vector of floating point values. Another way to think of an embedding is as \"lookup table\". After these weights have been learned, you can encode each word by looking up the dense vector it corresponds to in the table."]},{"cell_type":"markdown","metadata":{"id":"SZUQErGewZxE"},"source":["## **Setup**"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-13T04:09:00.027127Z","iopub.status.busy":"2021-01-13T04:09:00.026402Z","iopub.status.idle":"2021-01-13T04:09:06.603000Z","shell.execute_reply":"2021-01-13T04:09:06.602369Z"},"id":"RutaI-Tpev3T"},"source":["import io\n","import os\n","import re\n","import shutil\n","import string\n","import tensorflow as tf\n","\n","from datetime import datetime\n","from tensorflow.keras import Model, Sequential\n","from tensorflow.keras.layers import Activation, Dense, Embedding, GlobalAveragePooling1D\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SBFctV8-JZOc"},"source":["### **Download the IMDb Dataset**\n","\n","You will use the [Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/) through the tutorial. You will train a sentiment classifier model on this dataset and in the process learn embeddings from scratch. To read more about loading a dataset from scratch, see the \n","\n","Download the dataset using Keras file utility and take a look at the directories."]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-13T04:09:06.609910Z","iopub.status.busy":"2021-01-13T04:09:06.609205Z","iopub.status.idle":"2021-01-13T04:09:27.313818Z","shell.execute_reply":"2021-01-13T04:09:27.314295Z"},"id":"aPO4_UmfF0KH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615303663221,"user_tz":-300,"elapsed":34607,"user":{"displayName":"Muhammad Huzaifa Shahbaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL4Ps3wLTV9qu8u5BVZJ6Wrjwhej60xEUkbxyG1kE=s64","userId":"13063659721300413814"}},"outputId":"a62702f8-185f-4950-ce0f-520063fd1f0e"},"source":["url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n","\n","dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url,\n","                                    untar=True, cache_dir='.',\n","                                    cache_subdir='')\n","\n","dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n","os.listdir(dataset_dir)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['imdbEr.txt', 'imdb.vocab', 'test', 'train', 'README']"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"eY6yROZNKvbd"},"source":["Take a look at the `train/` directory. It has `pos` and `neg` folders with movie reviews labelled as positive and negative respectively. You will use reviews from `pos` and `neg` folders to train a binary classification model."]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-13T04:09:27.319864Z","iopub.status.busy":"2021-01-13T04:09:27.319178Z","iopub.status.idle":"2021-01-13T04:09:27.321853Z","shell.execute_reply":"2021-01-13T04:09:27.322302Z"},"id":"9-iOHJGN6SDu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615303663222,"user_tz":-300,"elapsed":34603,"user":{"displayName":"Muhammad Huzaifa Shahbaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL4Ps3wLTV9qu8u5BVZJ6Wrjwhej60xEUkbxyG1kE=s64","userId":"13063659721300413814"}},"outputId":"8c479632-1b5e-4b40-f4d0-3eabf8cdbb89"},"source":["train_dir = os.path.join(dataset_dir, 'train')\n","os.listdir(train_dir)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['pos',\n"," 'unsup',\n"," 'neg',\n"," 'urls_neg.txt',\n"," 'labeledBow.feat',\n"," 'unsupBow.feat',\n"," 'urls_unsup.txt',\n"," 'urls_pos.txt']"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"9O59BdioK8jY"},"source":["The `train` directory also has additional folders which should be removed before creating training dataset."]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-13T04:09:27.326807Z","iopub.status.busy":"2021-01-13T04:09:27.326131Z","iopub.status.idle":"2021-01-13T04:09:28.221686Z","shell.execute_reply":"2021-01-13T04:09:28.221008Z"},"id":"1_Vfi9oWMSh-"},"source":["remove_dir = os.path.join(train_dir, 'unsup')\n","shutil.rmtree(remove_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oFoJjiEyJz9u"},"source":["Next, create a `tf.data.Dataset` using `tf.keras.preprocessing.text_dataset_from_directory`. You can read more about using this utility in this [text classification tutorial](https://www.tensorflow.org/tutorials/keras/text_classification). \n","\n","Use the `train` directory to create both train and validation datasets with a split of 20% for validation."]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-13T04:09:28.227987Z","iopub.status.busy":"2021-01-13T04:09:28.227113Z","iopub.status.idle":"2021-01-13T04:09:31.882831Z","shell.execute_reply":"2021-01-13T04:09:31.882253Z"},"id":"ItYD3TLkCOP1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615303682733,"user_tz":-300,"elapsed":54108,"user":{"displayName":"Muhammad Huzaifa Shahbaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL4Ps3wLTV9qu8u5BVZJ6Wrjwhej60xEUkbxyG1kE=s64","userId":"13063659721300413814"}},"outputId":"1f1101ad-2fdd-45fd-c85b-436f14bdb607"},"source":["batch_size = 1024\n","seed = 123\n","train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n","    'aclImdb/train', batch_size=batch_size, validation_split=0.2, \n","    subset='training', seed=seed)\n","val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n","    'aclImdb/train', batch_size=batch_size, validation_split=0.2, \n","    subset='validation', seed=seed)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 25000 files belonging to 2 classes.\n","Using 20000 files for training.\n","Found 25000 files belonging to 2 classes.\n","Using 5000 files for validation.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eHa6cq0-Ym0g"},"source":["Take a look at a few movie reviews and their labels `(1: positive, 0: negative)` from the train dataset.\n"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-13T04:09:31.888110Z","iopub.status.busy":"2021-01-13T04:09:31.887383Z","iopub.status.idle":"2021-01-13T04:09:32.278989Z","shell.execute_reply":"2021-01-13T04:09:32.278358Z"},"id":"aTCbSkvkYmTT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615303745931,"user_tz":-300,"elapsed":823,"user":{"displayName":"Muhammad Huzaifa Shahbaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL4Ps3wLTV9qu8u5BVZJ6Wrjwhej60xEUkbxyG1kE=s64","userId":"13063659721300413814"}},"outputId":"e52a2400-0cbe-48ad-e8d4-6e9058322ffd"},"source":["for text_batch, label_batch in train_ds.take(1):\n","  for i in range(10):\n","    print(label_batch[i].numpy(), text_batch.numpy()[i])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 b\"Wow. Some movies just leave me speechless. This was undeniably one of those movies. When I left the theatre, not a single word came to my mouth. All I had was an incredible urge to slam my head against the theatre wall to help me forget about the last hour and a half. Unfortunately, it didn't work. Honestly, this movie has nothing to recommend. The humor was at the first grade level, at best, the acting was overly silly, and the plot was astronomically far-fetched. I hearby pledge never to see an other movie starring Chris Kattan or any other cast-member of SNL.\"\n","1 b'If any show in the last ten years deserves a 10, it is this rare gem. It allows us to escape back to a time when things were simpler and more fun. Filled with heart and laughs, this show keeps you laughing through the three decades of difference. The furniture was ugly, the clothes were colorful, and the even the drugs were tolerable. The hair was feathered, the music was accompanied by roller-skates, and in the words of Merle Haggard, \"a joint was a bad place to be\". Take a trip back to the greatest time in American history. Fall in love with characters and the feel good essence of the small town where people were nicer to each other. This classic is on television as much as \"Full House\". Don\\'t miss it, and always remember to \"Shake your groove thing!!!\"'\n","1 b'Clearly an hilarious movie.<br /><br />It angers me to see the poor ratings given to this piece of comic genius<br /><br />Please look at this for what it is, a funny, ridiculous enjoyable film. Laugh for christ sake!<br /><br />'\n","0 b\"Distasteful, cliched thriller has young couple doing cross-country research on America's most infamous murder sites, becoming road partners with a dim-witted young woman and her snarling boyfriend--who is an actual psycho. Arty and alienating, the film's tone alternates between pouty pseudo-irony and silly flamboyance. Handsomely-made perhaps, but ultimately laughable. Brad Pitt's performance as the low-rent killer is godawful. * from ****\"\n","1 b\"Scott is right. The best 2 person sword duel ever put on film is in the middle of this movie. The sword fights with multiple fighters are not the best although quite good. However, the fight in the middle is the best even compared to Japanese samurai movies. Chinese swordplay scenes in my opinion have never surpassed the Japanese in terms of entertainment value. Especially in scenes where one guy must battle a group of enemies, Japanese movies excel, example being the Lone Wolf and Cub series. Even though duels in Japanese cinema last only seconds or a minute at the most, the sheer intensity of those moments made them better. But, this is one example where Chinese swordplay surpasses the Japanese. The scene in the middle of this film was a five minute long fight with the most amazing choreography ever. The other fights in this movie are good too but even if they sucked this movie would get a 7 for that one scene. If you haven't seen it, you have to. John Woo is the man.\"\n","0 b'An archaeologist (Casper Van Dien) stumbles accidentally upon an ancient, 40 foot mummy, well preserved underground in the Nevada desert. They are determined to keep this a secret and call in a Jewish translator to assist in figuring out the history of it. The mummy, as explained at the beginning, is the son of a fallen angel and is one of several giants that apparently existed in \"those days\". In order to save his son from a devastating flood which was predicted to kill everything, he mummifies his son, burying him with several servants for centuries - planning to awaken him years from then. In our present, the fallen angels still walk the earth and the mummy is resurrected and a ritual is expected to take place. Most of the movie is slow, having to do with a lot of biblical crap and a couple lousy, air-punching fights. The mummy is decent looking but isn\\'t shown nearly enough. It should have had more to do with that but it dragged on a great deal so... eh. Don\\'t bother.'\n","0 b'I understand that this movie is made for kids and as a parent I have sat through many movies that don\\'t particularly hold my interest, but I can appreciate from a constructive point of view in how it is being received by my children. Parents are supposed to be encouraged after all to take part in their children\\'s activities and to monitor the quality of the entertainment that they view so there should be something that appeals to an adult audience on some level even in children\\'s movies. Disney has always understood this which is why it is so hard to fathom how it could allow such a complete piece of drek to bear their name.<br /><br />Technically, the sound editing is horrible and all dialog sounds over-dubbed and unnatural. Personally I hate that, but it was doubly awful considering the dialog itself seemed as though it was written by a 12 year old for a school project. The \"acting\" reminded me of a school play and none of the child actors had any range of emotion in their voices. Thankfully it was a very short movie.<br /><br />Now, before I come off like a video-geek measuring a kids movie with an adult yard stick, the one thing that can save even the worst children\\'s movie is a positive message. Far be it from me to determine how a message has to be delivered so long as the right one is. Let us take a walk through this film to see what messages are given: <br /><br />If you are lost, don\\'t worry, you will inevitably find your way home.<br /><br />Approach wild animals without any fear.<br /><br />You can win any competition just because you \"know\" you can.<br /><br />and my favorite, the final message left in the film: <br /><br />It\\'s okay to disobey authority figures and do what you think is right.'\n","0 b'I only saw this movie once, and that was enough for me. The movie has very little if any plot and seems to be nothing but continuous scenes of psycho-sadistic violence and very little of anything else. I wanted to see this movie because it starred Zoe Trilling of the second \"Night of The Demons;\" and I wanted to see her playing someone normal. Unfortunately, the Tobe Hooper script barely begins and goes nowhere as Robert Englund dominates the film and chews up the scenery and plot. Zoe, I know where you are now; hiding from this film !'\n","0 b'This movie is little more than poorly-made, fetish porn, and this is saying a lot considering the similar crap that was made in that era. This was recommended to me by friend as a \"unique film experience.\" He was right. I suppose he meant that as a joke. Not disgusting, not even that shocking. Just mediocre acting and poor attempts at shock art. A little bit of camp value, though I don\\'t believe the makers of this film intended this. And yes, as a previous reviewer mentioned, it\\'s sex with a guy in a bear suit. Don\\'t spend a lot of money on this. Try to borrow it, if you must see it. Or contact me, I\\'d be happy to sell you my copy for half price.<br /><br />I may have to see another of this particular director\\'s films, as he seems to have a certain following. But if it\\'s anything like this, I will again regret another 2 hours of my life gone forever.'\n","1 b\"Excellent film that reveals how people are connected to the taken for granted, ordinary beads exchanged during Mardi Gras. The film is much more than a commentary on globalization. In fact, it humanizes the workers in China, the owner of the factory, the bead distributor in New Orleans, and even the revelers in New Orleans. What stands out the most is the director's ability to tell a tricky story with complicated details in such a simple and seductive way. His amazing access to the factory is another aspect that's intriguing and I only wish I knew how he got inside. It's a beautiful story without sentimentality or guilt associated with it, and the conclusion provides hope without leaving people feeling alienated.\"\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FHV2pchDhzDn"},"source":["### **Configure the dataset for performance**\n","\n","These are two important methods you should use when loading data to make sure that I/O does not become blocking.\n","\n","`.cache()` keeps data in memory after it's loaded off disk. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache, which is more efficient to read than many small files.\n","\n","`.prefetch()` overlaps data preprocessing and model execution while training. \n","\n","You can learn more about both methods, as well as how to cache data to disk in the [data performance guide](https://www.tensorflow.org/guide/data_performance)."]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-13T04:09:32.284161Z","iopub.status.busy":"2021-01-13T04:09:32.283401Z","iopub.status.idle":"2021-01-13T04:09:32.286803Z","shell.execute_reply":"2021-01-13T04:09:32.287252Z"},"id":"Oz6k1IW7h1TO"},"source":["AUTOTUNE = tf.data.AUTOTUNE\n","\n","train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7cgn3fMenQfu","executionInfo":{"status":"ok","timestamp":1615303876558,"user_tz":-300,"elapsed":1497,"user":{"displayName":"Muhammad Huzaifa Shahbaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL4Ps3wLTV9qu8u5BVZJ6Wrjwhej60xEUkbxyG1kE=s64","userId":"13063659721300413814"}},"outputId":"ee19d8e6-e212-4f5a-fef2-304d6f875385"},"source":["AUTOTUNE"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-1"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"markdown","metadata":{"id":"eqBazMiVQkj1"},"source":["## **Using the Embedding layer**\n","\n","Keras makes it easy to use word embeddings. Take a look at the [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer.\n","\n","The Embedding layer can be understood as a lookup table that maps from integer indices (which stand for specific words) to dense vectors (their embeddings). The dimensionality (or width) of the embedding is a parameter you can experiment with to see what works well for your problem, much in the same way you would experiment with the number of neurons in a Dense layer.\n"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-13T04:09:32.291492Z","iopub.status.busy":"2021-01-13T04:09:32.290814Z","iopub.status.idle":"2021-01-13T04:09:32.301978Z","shell.execute_reply":"2021-01-13T04:09:32.301448Z"},"id":"-OjxLVrMvWUE"},"source":["# Embed a 1,000 word vocabulary into 5 dimensions.\n","embedding_layer = tf.keras.layers.Embedding(1000, 5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2dKKV1L2Rk7e"},"source":["When you create an Embedding layer, the weights for the embedding are randomly initialized (just like any other layer). During training, they are gradually adjusted via backpropagation. Once trained, the learned word embeddings will roughly encode similarities between words (as they were learned for the specific problem your model is trained on).\n","\n","If you pass an integer to an embedding layer, the result replaces each integer with the vector from the embedding table:"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-13T04:09:32.307339Z","iopub.status.busy":"2021-01-13T04:09:32.306648Z","iopub.status.idle":"2021-01-13T04:09:32.315475Z","shell.execute_reply":"2021-01-13T04:09:32.314950Z"},"id":"0YUjPgP7w0PO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615303948329,"user_tz":-300,"elapsed":750,"user":{"displayName":"Muhammad Huzaifa Shahbaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL4Ps3wLTV9qu8u5BVZJ6Wrjwhej60xEUkbxyG1kE=s64","userId":"13063659721300413814"}},"outputId":"87a56f22-8899-4271-8c4a-149a51fd5369"},"source":["result = embedding_layer(tf.constant([1,2,3]))\n","result.numpy()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-0.00311515, -0.03468014, -0.0262353 ,  0.02020203,  0.01979509],\n","       [ 0.02461963, -0.02254214,  0.00395045, -0.04669213, -0.0005152 ],\n","       [-0.03816022,  0.00461972, -0.01900642, -0.01457835,  0.02912059]],\n","      dtype=float32)"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"markdown","metadata":{"id":"O4PC4QzsxTGx"},"source":["For text or sequence problems, the Embedding layer takes a 2D tensor of integers, of shape `(samples, sequence_length)`, where each entry is a sequence of integers. It can embed sequences of variable lengths. You could feed into the embedding layer above batches with shapes `(32, 10)` (batch of 32 sequences of length 10) or `(64, 15)` (batch of 64 sequences of length 15).\n","\n","The returned tensor has one more axis than the input, the embedding vectors are aligned along the new last axis. Pass it a `(2, 3)` input batch and the output is `(2, 3, N)`\n"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-13T04:09:32.320306Z","iopub.status.busy":"2021-01-13T04:09:32.319594Z","iopub.status.idle":"2021-01-13T04:09:32.322874Z","shell.execute_reply":"2021-01-13T04:09:32.323319Z"},"id":"vwSYepRjyRGy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615304094375,"user_tz":-300,"elapsed":2692,"user":{"displayName":"Muhammad Huzaifa Shahbaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL4Ps3wLTV9qu8u5BVZJ6Wrjwhej60xEUkbxyG1kE=s64","userId":"13063659721300413814"}},"outputId":"e1c52893-b8af-4d1f-dcfb-727fc7131954"},"source":["result = embedding_layer(tf.constant([[0,1,2],[3,4,5]]))\n","result.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([2, 3, 5])"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"WGQp2N92yOyB"},"source":["When given a batch of sequences as input, an embedding layer returns a 3D floating point tensor, of shape `(samples, sequence_length, embedding_dimensionality)`. To convert from this sequence of variable length to a fixed representation there are a variety of standard approaches. You could use an RNN, Attention, or pooling layer before passing it to a Dense layer. This tutorial uses pooling because it's the simplest. "]},{"cell_type":"markdown","metadata":{"id":"aGicgV5qT0wh"},"source":["## **Text preprocessing**"]},{"cell_type":"markdown","metadata":{"id":"N6NZSqIIoU0Y"},"source":["Next, define the dataset preprocessing steps required for your sentiment classification model. Initialize a TextVectorization layer with the desired parameters to vectorize movie reviews. You can learn more about using this layer in the [Text Classification](https://www.tensorflow.org/tutorials/keras/text_classification) tutorial."]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-13T04:09:32.345692Z","iopub.status.busy":"2021-01-13T04:09:32.342229Z","iopub.status.idle":"2021-01-13T04:09:35.492916Z","shell.execute_reply":"2021-01-13T04:09:35.493403Z"},"id":"2MlsXzo-ZlfK"},"source":["# Create a custom standardization function to strip HTML break tags '<br />'.\n","def custom_standardization(input_data):\n","  lowercase = tf.strings.lower(input_data)\n","  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n","  return tf.strings.regex_replace(stripped_html,\n","                                  '[%s]' % re.escape(string.punctuation), '')\n","\n","# Vocabulary size and number of words in a sequence.\n","vocab_size = 10000\n","sequence_length = 100\n","\n","# Use the text vectorization layer to normalize, split, and map strings to \n","# integers. Note that the layer uses the custom standardization defined above. \n","# Set maximum_sequence length as all samples are not of the same length.\n","vectorize_layer = TextVectorization(\n","    standardize=custom_standardization,\n","    max_tokens=vocab_size,\n","    output_mode='int',\n","    output_sequence_length=sequence_length)\n","\n","# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n","text_ds = train_ds.map(lambda x, y: x)\n","vectorize_layer.adapt(text_ds)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zI9_wLIiWO8Z"},"source":["## **Create a classification model**\n","\n","Use the [Keras Sequential API](../../guide/keras) to define the sentiment classification model. In this case it is a \"Continuous bag of words\" style model.\n","* The [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) layer transforms strings into vocabulary indices. You have already initialized `vectorize_layer` as a TextVectorization layer and built it's vocabulary by calling `adapt` on `text_ds`. Now vectorize_layer can be used as the first layer of your end-to-end classification model, feeding tranformed strings into the Embedding layer.\n","* The [`Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer takes the integer-encoded vocabulary and looks up the embedding vector for each word-index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: `(batch, sequence, embedding)`.\n","\n","* The [`GlobalAveragePooling1D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling1D) layer returns a fixed-length output vector for each example by averaging over the sequence dimension. This allows the model to handle input of variable length, in the simplest way possible.\n","\n","* The fixed-length output vector is piped through a fully-connected ([`Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)) layer with 16 hidden units.\n","\n","* The last layer is densely connected with a single output node. \n","\n","Caution: This model doesn't use masking, so the zero-padding is used as part of the input and hence the padding length may affect the output.  To fix this, see the [masking and padding guide](../../guide/keras/masking_and_padding)."]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-13T04:09:35.510031Z","iopub.status.busy":"2021-01-13T04:09:35.509235Z","iopub.status.idle":"2021-01-13T04:09:35.514781Z","shell.execute_reply":"2021-01-13T04:09:35.514166Z"},"id":"pHLcFtn5Wsqj"},"source":["embedding_dim=16\n","\n","model = Sequential([\n","  vectorize_layer,\n","  Embedding(vocab_size, embedding_dim, name=\"embedding\"),\n","  GlobalAveragePooling1D(), #RNN OR CNN OR ATTENTION \n","  Dense(16, activation='relu'),\n","  Dense(1)\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JjLNgKO7W2fe"},"source":["## **Compile and train the model**"]},{"cell_type":"markdown","metadata":{"id":"jpX9etB6IOQd"},"source":["You will use [TensorBoard](https://www.tensorflow.org/tensorboard) to visualize metrics including loss and accuracy. Create a `tf.keras.callbacks.TensorBoard`."]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-13T04:09:35.520770Z","iopub.status.busy":"2021-01-13T04:09:35.520091Z","iopub.status.idle":"2021-01-13T04:09:35.522572Z","shell.execute_reply":"2021-01-13T04:09:35.521972Z"},"id":"W4Hg3IHFt4Px"},"source":["tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7OrKAKAKIbuH"},"source":["Compile and train the model using the `Adam` optimizer and `BinaryCrossentropy` loss. "]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-13T04:09:35.537946Z","iopub.status.busy":"2021-01-13T04:09:35.537179Z","iopub.status.idle":"2021-01-13T04:09:35.547747Z","shell.execute_reply":"2021-01-13T04:09:35.548233Z"},"id":"lCUgdP69Wzix"},"source":["model.compile(optimizer='adam',\n","              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-13T04:09:35.553172Z","iopub.status.busy":"2021-01-13T04:09:35.552452Z","iopub.status.idle":"2021-01-13T04:10:00.939480Z","shell.execute_reply":"2021-01-13T04:10:00.938836Z"},"id":"5mQehiQyv8rP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615304763055,"user_tz":-300,"elapsed":34369,"user":{"displayName":"Muhammad Huzaifa Shahbaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL4Ps3wLTV9qu8u5BVZJ6Wrjwhej60xEUkbxyG1kE=s64","userId":"13063659721300413814"}},"outputId":"bea244f2-1afa-4903-cd60-7ff8cac3ed50"},"source":["model.fit(\n","    train_ds,\n","    validation_data=val_ds, \n","    epochs=20,\n","    callbacks=[tensorboard_callback])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","20/20 [==============================] - 3s 105ms/step - loss: 0.6925 - accuracy: 0.5037 - val_loss: 0.6897 - val_accuracy: 0.4886\n","Epoch 2/20\n","20/20 [==============================] - 2s 81ms/step - loss: 0.6876 - accuracy: 0.5037 - val_loss: 0.6826 - val_accuracy: 0.4886\n","Epoch 3/20\n","20/20 [==============================] - 2s 80ms/step - loss: 0.6790 - accuracy: 0.5037 - val_loss: 0.6713 - val_accuracy: 0.4886\n","Epoch 4/20\n","20/20 [==============================] - 2s 80ms/step - loss: 0.6655 - accuracy: 0.5037 - val_loss: 0.6549 - val_accuracy: 0.4886\n","Epoch 5/20\n","20/20 [==============================] - 2s 80ms/step - loss: 0.6461 - accuracy: 0.5037 - val_loss: 0.6334 - val_accuracy: 0.4886\n","Epoch 6/20\n","20/20 [==============================] - 2s 78ms/step - loss: 0.6206 - accuracy: 0.5038 - val_loss: 0.6070 - val_accuracy: 0.4920\n","Epoch 7/20\n","20/20 [==============================] - 2s 79ms/step - loss: 0.5900 - accuracy: 0.5295 - val_loss: 0.5782 - val_accuracy: 0.5890\n","Epoch 8/20\n","20/20 [==============================] - 2s 79ms/step - loss: 0.5564 - accuracy: 0.6364 - val_loss: 0.5488 - val_accuracy: 0.6470\n","Epoch 9/20\n","20/20 [==============================] - 2s 79ms/step - loss: 0.5221 - accuracy: 0.7031 - val_loss: 0.5208 - val_accuracy: 0.6908\n","Epoch 10/20\n","20/20 [==============================] - 2s 78ms/step - loss: 0.4890 - accuracy: 0.7459 - val_loss: 0.4954 - val_accuracy: 0.7228\n","Epoch 11/20\n","20/20 [==============================] - 2s 80ms/step - loss: 0.4583 - accuracy: 0.7792 - val_loss: 0.4732 - val_accuracy: 0.7460\n","Epoch 12/20\n","20/20 [==============================] - 2s 79ms/step - loss: 0.4306 - accuracy: 0.8017 - val_loss: 0.4542 - val_accuracy: 0.7610\n","Epoch 13/20\n","20/20 [==============================] - 2s 80ms/step - loss: 0.4059 - accuracy: 0.8187 - val_loss: 0.4384 - val_accuracy: 0.7704\n","Epoch 14/20\n","20/20 [==============================] - 2s 78ms/step - loss: 0.3840 - accuracy: 0.8343 - val_loss: 0.4252 - val_accuracy: 0.7800\n","Epoch 15/20\n","20/20 [==============================] - 2s 85ms/step - loss: 0.3644 - accuracy: 0.8451 - val_loss: 0.4143 - val_accuracy: 0.7896\n","Epoch 16/20\n","20/20 [==============================] - 2s 79ms/step - loss: 0.3470 - accuracy: 0.8533 - val_loss: 0.4054 - val_accuracy: 0.7972\n","Epoch 17/20\n","20/20 [==============================] - 2s 78ms/step - loss: 0.3313 - accuracy: 0.8613 - val_loss: 0.3982 - val_accuracy: 0.8014\n","Epoch 18/20\n","20/20 [==============================] - 2s 81ms/step - loss: 0.3171 - accuracy: 0.8689 - val_loss: 0.3925 - val_accuracy: 0.8050\n","Epoch 19/20\n","20/20 [==============================] - 2s 79ms/step - loss: 0.3042 - accuracy: 0.8757 - val_loss: 0.3879 - val_accuracy: 0.8078\n","Epoch 20/20\n","20/20 [==============================] - 2s 78ms/step - loss: 0.2924 - accuracy: 0.8812 - val_loss: 0.3845 - val_accuracy: 0.8118\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f77f60fa490>"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"markdown","metadata":{"id":"1wYnVedSPfmX"},"source":["With this approach the model reaches a validation accuracy of around 88% (note that the model is overfitting since training accuracy is higher).\n","\n","Note: Your results may be a bit different, depending on how weights were randomly initialized before training the embedding layer. \n","\n","You can look into the model summary to learn more about each layer of the model."]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-13T04:10:00.945328Z","iopub.status.busy":"2021-01-13T04:10:00.944605Z","iopub.status.idle":"2021-01-13T04:10:00.949159Z","shell.execute_reply":"2021-01-13T04:10:00.948611Z"},"id":"mDCgjWyq_0dc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615304781318,"user_tz":-300,"elapsed":1137,"user":{"displayName":"Muhammad Huzaifa Shahbaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL4Ps3wLTV9qu8u5BVZJ6Wrjwhej60xEUkbxyG1kE=s64","userId":"13063659721300413814"}},"outputId":"1b3c3ad0-8cd3-4218-830d-33113b4655a6"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","text_vectorization_2 (TextVe (None, 100)               0         \n","_________________________________________________________________\n","embedding (Embedding)        (None, 100, 16)           160000    \n","_________________________________________________________________\n","global_average_pooling1d_3 ( (None, 16)                0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 16)                272       \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 1)                 17        \n","=================================================================\n","Total params: 160,289\n","Trainable params: 160,289\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hiQbOJZ2WBFY"},"source":["Visualize the model metrics in TensorBoard."]},{"cell_type":"markdown","metadata":{"id":"KCoA6qwqP836"},"source":["## **Retrieve the trained word embeddings and save them to disk**\n","\n","Next, retrieve the word embeddings learned during training. The embeddings are weights of the Embedding layer in the model. The weights matrix is of shape `(vocab_size, embedding_dimension)`."]},{"cell_type":"markdown","metadata":{"id":"Zp5rv01WG2YA"},"source":["Obtain the weights from the model using `get_layer()` and `get_weights()`. The `get_vocabulary()` function provides the vocabulary to build a metadata file with one token per line. "]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-13T04:10:00.954426Z","iopub.status.busy":"2021-01-13T04:10:00.953719Z","iopub.status.idle":"2021-01-13T04:10:00.969888Z","shell.execute_reply":"2021-01-13T04:10:00.969296Z"},"id":"_Uamp1YH8RzU","executionInfo":{"status":"ok","timestamp":1615304909520,"user_tz":-300,"elapsed":1414,"user":{"displayName":"Muhammad Huzaifa Shahbaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL4Ps3wLTV9qu8u5BVZJ6Wrjwhej60xEUkbxyG1kE=s64","userId":"13063659721300413814"}}},"source":["weights = model.get_layer('embedding').get_weights()[0]\n","vocab = vectorize_layer.get_vocabulary()"],"execution_count":66,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J8MiCA77X8B8"},"source":["Write the weights to disk. To use the [Embedding Projector](http://projector.tensorflow.org), you will upload two files in tab separated format: a file of vectors (containing the embedding), and a file of meta data (containing the words)."]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-13T04:10:00.975706Z","iopub.status.busy":"2021-01-13T04:10:00.974988Z","iopub.status.idle":"2021-01-13T04:10:01.112373Z","shell.execute_reply":"2021-01-13T04:10:01.112873Z"},"id":"VLIahl9s53XT","executionInfo":{"status":"ok","timestamp":1615305023820,"user_tz":-300,"elapsed":1439,"user":{"displayName":"Muhammad Huzaifa Shahbaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL4Ps3wLTV9qu8u5BVZJ6Wrjwhej60xEUkbxyG1kE=s64","userId":"13063659721300413814"}}},"source":["out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n","out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n","\n","for index, word in enumerate(vocab):\n","  if  index == 0: continue # skip 0, it's padding.\n","  vec = weights[index] \n","  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n","  out_m.write(word + \"\\n\")\n","out_v.close()\n","out_m.close()"],"execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-01-13T04:10:01.118153Z","iopub.status.busy":"2021-01-13T04:10:01.117410Z","iopub.status.idle":"2021-01-13T04:10:01.119783Z","shell.execute_reply":"2021-01-13T04:10:01.119280Z"},"id":"lUsjQOKMIV2z","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1615305046117,"user_tz":-300,"elapsed":1440,"user":{"displayName":"Muhammad Huzaifa Shahbaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL4Ps3wLTV9qu8u5BVZJ6Wrjwhej60xEUkbxyG1kE=s64","userId":"13063659721300413814"}},"outputId":"f9cccdda-3a11-44fd-f8e5-d43dc26416d9"},"source":["try:\n","  from google.colab import files\n","  files.download('vectors.tsv')\n","  files.download('metadata.tsv')\n","except Exception as e:\n","  pass"],"execution_count":68,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_cf3fe49e-48ba-4a39-8fdb-36fb255bab99\", \"vectors.tsv\", 1874337)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_363c6263-f9bc-4aa1-a70b-c912a509febb\", \"metadata.tsv\", 76492)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"PXLfFA54Yz-o"},"source":["## Visualize the embeddings\n","\n","To visualize the embeddings, upload them to the embedding projector.\n","\n","Open the [Embedding Projector](http://projector.tensorflow.org/) (this can also run in a local TensorBoard instance).\n","\n","* Click on \"Load data\".\n","\n","* Upload the two files you created above: `vecs.tsv` and `meta.tsv`.\n","\n","The embeddings you have trained will now be displayed. You can search for words to find their closest neighbors. For example, try searching for \"beautiful\". You may see neighbors like \"wonderful\". \n","\n","Note: Experimentally, you may be able to produce more interpretable embeddings by using a simpler model. Try deleting the `Dense(16)` layer, retraining the model, and visualizing the embeddings again.\n","\n","Note: Typically, a much larger dataset is needed to train more interpretable word embeddings. This tutorial uses a small IMDb dataset for the purpose of demonstration.\n"]}]}